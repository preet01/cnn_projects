{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import get_CIFAR10_data\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer,Input\n",
    "from tensorflow.python.keras.layers import Reshape,MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D,Dense,Flatten\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data['X_train']\n",
    "y_train=data['y_train']\n",
    "X_val=data['X_val']\n",
    "y_val=data['y_val']\n",
    "X_test=data['X_test']\n",
    "y_test=data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(data['y_train'],num_classes=10)\n",
    "y_val=to_categorical(data['y_val'],num_classes=10)\n",
    "y_test=to_categorical(data['y_test'],num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing X\n",
    "X_train = X_train.astype('float32')\n",
    "X_val= X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_val/=255.0\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=np.reshape(X_val,(-1,32,32,3))\n",
    "X_test=np.reshape(X_test,(-1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(kernel_size=5,strides=1,filters=16,padding='same',activation='relu',name='Conv-1'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu',name='dense-1'))\n",
    "model.add(Dense(10,activation='softmax',name='dense-2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(kernel_size=5,strides=1,filters=32,padding='same',activation='relu',name='Conv-1'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "\n",
    "model.add(Conv2D(kernel_size=5,strides=1,filters=64,padding='same',activation='relu',name='Conv-2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024,activation='relu',name='dense-1'))\n",
    "model.add(Dense(10,activation='softmax',name='dense-2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "Conv-1 (Conv2D)              (None, 32, 32, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense-1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense-2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,104,010\n",
      "Trainable params: 2,104,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.optimizers import Adam\n",
    "optimizer=Adam(lr=1e-4,decay=1e-6)\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49000/49000 [==============================]49000/49000 [==============================] - 81s 2ms/step - loss: 2.1355 - acc: 0.2329\n",
      "\n",
      "Epoch 2/5\n",
      "49000/49000 [==============================]49000/49000 [==============================] - 79s 2ms/step - loss: 1.9616 - acc: 0.2974\n",
      "\n",
      "Epoch 3/5\n",
      "49000/49000 [==============================]49000/49000 [==============================] - 97s 2ms/step - loss: 1.8943 - acc: 0.3262\n",
      "\n",
      "Epoch 4/5\n",
      "49000/49000 [==============================]49000/49000 [==============================] - 91s 2ms/step - loss: 1.8249 - acc: 0.3543\n",
      "\n",
      "Epoch 5/5\n",
      "49000/49000 [==============================]49000/49000 [==============================] - 80s 2ms/step - loss: 1.7669 - acc: 0.3706\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fa7bed60390>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,num_classes=10,epochs=5,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_augmentation=True\n",
    "steps=int(X_train.shape[0]/64)\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/20\n",
      "765/765 [==============================] - 19s 24ms/step - loss: 1.9060 - acc: 0.3122 - val_loss: 1.6535 - val_acc: 0.4120\n",
      "Epoch 2/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.7465 - acc: 0.3709 - val_loss: 1.5745 - val_acc: 0.4480\n",
      "Epoch 3/20\n",
      "765/765 [==============================] - 16s 20ms/step - loss: 1.6917 - acc: 0.3952 - val_loss: 1.5270 - val_acc: 0.4850\n",
      "Epoch 4/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.6443 - acc: 0.4150 - val_loss: 1.4797 - val_acc: 0.4870\n",
      "Epoch 5/20\n",
      "765/765 [==============================] - 16s 20ms/step - loss: 1.6189 - acc: 0.4261 - val_loss: 1.4079 - val_acc: 0.4930\n",
      "Epoch 6/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.5917 - acc: 0.4357 - val_loss: 1.4286 - val_acc: 0.4960\n",
      "Epoch 7/20\n",
      "765/765 [==============================] - 16s 21ms/step - loss: 1.5684 - acc: 0.4420 - val_loss: 1.3910 - val_acc: 0.5180\n",
      "Epoch 8/20\n",
      "765/765 [==============================] - 16s 20ms/step - loss: 1.5509 - acc: 0.4471 - val_loss: 1.4021 - val_acc: 0.5070\n",
      "Epoch 9/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.5280 - acc: 0.4570 - val_loss: 1.3761 - val_acc: 0.5150\n",
      "Epoch 10/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.5162 - acc: 0.4612 - val_loss: 1.3474 - val_acc: 0.5210\n",
      "Epoch 11/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.4930 - acc: 0.4702 - val_loss: 1.3413 - val_acc: 0.5250\n",
      "Epoch 12/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.4849 - acc: 0.4739 - val_loss: 1.3280 - val_acc: 0.5340\n",
      "Epoch 13/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.4686 - acc: 0.4782 - val_loss: 1.3221 - val_acc: 0.5380\n",
      "Epoch 14/20\n",
      "765/765 [==============================] - 16s 20ms/step - loss: 1.4554 - acc: 0.4850 - val_loss: 1.3147 - val_acc: 0.5190\n",
      "Epoch 15/20\n",
      "765/765 [==============================] - 16s 21ms/step - loss: 1.4398 - acc: 0.4899 - val_loss: 1.2864 - val_acc: 0.5480\n",
      "Epoch 16/20\n",
      "765/765 [==============================] - 16s 21ms/step - loss: 1.4280 - acc: 0.4936 - val_loss: 1.3145 - val_acc: 0.5380\n",
      "Epoch 17/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.4147 - acc: 0.4974 - val_loss: 1.2857 - val_acc: 0.5240\n",
      "Epoch 18/20\n",
      "765/765 [==============================] - 16s 21ms/step - loss: 1.4124 - acc: 0.4999 - val_loss: 1.2581 - val_acc: 0.5500\n",
      "Epoch 19/20\n",
      "765/765 [==============================] - 16s 21ms/step - loss: 1.4005 - acc: 0.5032 - val_loss: 1.2615 - val_acc: 0.5300\n",
      "Epoch 20/20\n",
      "765/765 [==============================] - 15s 20ms/step - loss: 1.3901 - acc: 0.5069 - val_loss: 1.2661 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,validation_data=(x_test, y_test),shuffle=True)\n",
    "\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "   # IT just computes the new generated images right now.\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, y_train,batch_size=64),epochs=20,validation_data=(X_val, y_val),workers=1,\n",
    "                       steps_per_epoch=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "765/765 [==============================] - 16s 21ms/step - loss: 1.3657 - acc: 0.5175 - val_loss: 1.2413 - val_acc: 0.5600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fa75402c710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since learning is a bit slow. Reinitialized the lr.\n",
    "optimizer=Adam(lr=1e-4,decay=1e-6)\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(X_train, y_train,batch_size=64),epochs=1,validation_data=(X_val, y_val),workers=1,\n",
    "                       steps_per_epoch=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "765/765 [==============================]765/765 [==============================] - 87s 114ms/step - loss: 1.8510 - acc: 0.3255 - val_loss: 1.6936 - val_acc: 0.4060\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7fa7be167f98>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, y_train,batch_size=64),epochs=1,validation_data=(X_val, y_val),workers=1,\n",
    "                       steps_per_epoch=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def plot_conv_weights(weights,input_channel=0):\n",
    "    \n",
    "    w=weights\n",
    "    \n",
    "    w_min=np.min(w)\n",
    "    w_max=np.max(w)\n",
    "    \n",
    "    num_filters=w.shape[3]\n",
    "    \n",
    "    num_grids=math.ceil(math.sqrt(num_filters))\n",
    "    \n",
    "    fig,axes=plt.subplots(num_grids,num_grids)\n",
    "    \n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        if i<num_filters:\n",
    "            img=w[:,:,input_channel,i]\n",
    "            \n",
    "            ax.imshow(img,vmin=w_min,vmax=w_max,interpolation='nearest',cmap='seismic')\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv1=model.layers[1]\n",
    "weights_conv1=layer_conv1.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD8CAYAAAA/iMxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7add30fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conv_weights(weights_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================]1000/1000 [==============================] - 1s 580us/step\n",
      "\n",
      "loss:1.6935678024291991,   accuracy:40.6\n"
     ]
    }
   ],
   "source": [
    "accuracy=model.evaluate(x=X_val,y=y_val)\n",
    "print('loss:{},   accuracy:{}'.format(float(accuracy[0]),accuracy[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
